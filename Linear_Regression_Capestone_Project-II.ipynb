{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1ZgOAj5EOUIsCLS7OlfXc80PzkoGn7FeN","timestamp":1674278877466},{"file_id":"10B2s5af8INkHgIz_7XBjW3iNDbGY7ltx","timestamp":1670998877439}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"TPU"},"cells":[{"cell_type":"markdown","source":["##### **Project Type -**  Regression \n","\n","##### **Presented By -** Suraj Kumar\n"],"metadata":{"id":"W6ess-Diz8mV"}},{"cell_type":"markdown","source":["# **Project Name**    - **SEOUL BIKE SHARING DEMAND PREDECTION**\n","\n"],"metadata":{"id":"vncDsAP0Gaoa"}},{"cell_type":"markdown","source":["Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it reduces the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes. Data description is the dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour, date information and attribute information."],"metadata":{"id":"XgKmr0fxx-UV"}},{"cell_type":"markdown","source":["# Variables\n","\n","**Date** : year-month-day\n","\n","**Rented Bike count** - Count of bikes rented at each hour\n","\n","**Hour** - Hour of the day\n","\n","**Temperature**-Temperature in Celsius\n","\n","**Humidity**- %\n","\n","**Windspeed** - m/s\n","\n","**Visibility** - 10m\n","\n","**Dew point temperature** - Celsius\n","\n","**Solar radiation** - MJ/m2\n","\n","**Rainfall** - mm\n","\n","**Snowfall** - cm\n","\n","**Seasons** - Winter, Spring, Summer, Autumn"],"metadata":{"id":"F6PBCcWkyM-S"}},{"cell_type":"markdown","source":["# **INTRODUCTION**"],"metadata":{"id":"a06BHOK0ZJlX"}},{"cell_type":"markdown","source":["This is the problem related to the regression prediction where we have to predict continuous target variable that is rented bike sales using the different independent variables related to the atmospheric condition.\n","\n","Here we will follow few norms for systemizing the approach to find the best prediction.\n","\n","1) Data Exploration and analysing pattern of relation among different variables.\n","\n","2) Removing outliers and dropping correlating variables.\n","\n","3) Defining target variables and features variables.\n","\n","4) Splitting the data for training and testing.\n","\n","5) Choosing the different model like linear regression, random forest regression, polynomial regression.\n","\n","6) Fitting the data and predicting result.\n","\n","7) Evaluation of the result using different metrics like Mean Squared Error,     R2_score etc.\n","\n","8) Hyper Parameter Tuning using Lasso, Ridge, Grid Search CV.\n","\n","9) Comparing different model with the help of metrics.\n","\n","10) Analysing importance of different features in prediction (Model explainability).\n","\n","11) Conclusion"],"metadata":{"id":"-uOv3RWQ0TOv"}},{"cell_type":"code","source":["# Import Libraries\n","import numpy as np\n","import pandas as pd\n","from numpy import math\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import mean_squared_error\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"M8Vqi-pPk-HR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Loading"],"metadata":{"id":"3RnN4peoiCZX"}},{"cell_type":"markdown","source":["Reading the file."],"metadata":{"id":"Zd071uVV6bCy"}},{"cell_type":"code","source":["# Load Dataset\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"4CkvbW_SlZ_R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path ='/content/drive/MyDrive/Capstone_Project-2/'"],"metadata":{"id":"KMH6AxupWisH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df=pd.read_csv(path+'SeoulBikeData.csv',encoding='unicode_escape') \n"],"metadata":{"id":"4lmE4xtRW8wl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset First View"],"metadata":{"id":"x71ZqKXriCWQ"}},{"cell_type":"code","source":["# Dataset First Look\n","df.head()"],"metadata":{"id":"LWNFOSvLl09H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Rows & Columns count"],"metadata":{"id":"7hBIi_osiCS2"}},{"cell_type":"code","source":["# Dataset Rows & Columns count\n","df.shape"],"metadata":{"id":"Kllu7SJgmLij"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Number of row=8760\n","\n","Number of columns=14"],"metadata":{"id":"9QGfKxZG6kHO"}},{"cell_type":"markdown","source":["### Dataset Information"],"metadata":{"id":"JlHwYmJAmNHm"}},{"cell_type":"code","source":["# Dataset Info\n","df.info"],"metadata":{"id":"e9hRXRi6meOf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Duplicate Values"],"metadata":{"id":"35m5QtbWiB9F"}},{"cell_type":"code","source":["# Dataset Duplicate Value Count\n","len(df[df.duplicated()])\n"],"metadata":{"id":"1sLdpKYkmox0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["No Duplicate Values."],"metadata":{"id":"NUJV-iXf65RF"}},{"cell_type":"markdown","source":["#### Missing Values/Null Values"],"metadata":{"id":"PoPl-ycgm1ru"}},{"cell_type":"code","source":["# Missing Values/Null Values Count\n","df.isna().sum().sum()"],"metadata":{"id":"GgHWkxvamxVg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["No Missing Values."],"metadata":{"id":"PeSK2dRm7E1l"}},{"cell_type":"code","source":["# Dataset Columns\n","df.columns"],"metadata":{"id":"j7xfkqrt5Ag5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exploratory Data Analysis"],"metadata":{"id":"BBq-HCSs-NDs"}},{"cell_type":"code","source":["# Dataset Describe\n","df.describe(include='all')\n"],"metadata":{"id":"DnOaZdaE5Q5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After looking at the mean, max and stadard value, it looks like it might contain many outliers."],"metadata":{"id":"p-OBq8vaDLLL"}},{"cell_type":"code","source":["#Dependent variable 'Rented Bike Count\n","plt.figure(figsize=(7,7))\n","sns.distplot(df['Rented Bike Count'],color='r')"],"metadata":{"id":"P2YEoBzwQa73"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After plotting the Density plot of number of rented bike, we can see that the majority is in between 100 to 1200 rented bikes with an outliers upto 3500.\n","\n","The density plot is positively skewed thus needs transformation for normalising the distribution of data."],"metadata":{"id":"LrOrzAH9Eq7l"}},{"cell_type":"code","source":["#skewness and kurtosis\n","print(\"Skewness: %f\" % df['Rented Bike Count'].skew())\n","print(\"Kurtosis: %f\" % df['Rented Bike Count'].kurt())"],"metadata":{"id":"SOfDmgAlvYj3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here skewness is 1.153 while the kurtosis is 0.853."],"metadata":{"id":"By4KzuC9Gb68"}},{"cell_type":"code","source":["#Reducing Skewness by root squaring target variables.\n","plt.figure(figsize=(7,7))\n","sns.distplot(np.sqrt(df['Rented Bike Count']),color='r')"],"metadata":{"id":"66SXWqwmJkgk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#skewness and kurtosis\n","print(\"Skewness after transformation: %f\" % np.sqrt(df['Rented Bike Count']).skew())\n","print(\"Kurtosis after transformation: %f\" % np.sqrt(df['Rented Bike Count']).kurt())"],"metadata":{"id":"ZZvvH5aCvxF2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After root squaring the target variable,we are able to reduce the Skewness to 0.23 and Kurtosis to -0.65."],"metadata":{"id":"ByVRW82dLMtR"}},{"cell_type":"markdown","source":["*Analysing the correlation between different numerical variables.*"],"metadata":{"id":"JHu24VL4MEQc"}},{"cell_type":"code","source":["#Relation Between Two Numerical Variables\n","sns.pairplot(df,vars=['Rented Bike Count','Hour','Temperature(Â°C)','Humidity(%)','Wind speed (m/s)','Visibility (10m)',], hue='Seasons')\n"],"metadata":{"id":"gWSXsLFezb6D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*First we need to convert the Date columns from string to date time format for data processing.*"],"metadata":{"id":"2i0Y4r3bWrTK"}},{"cell_type":"code","source":["# Write your code to make your dataset analysis ready.\n","#Convert the Date column in Datetime Dtype\n","df['Date']=pd.to_datetime(df['Date'])\n","\n","#Breaking Down the Date into 3 Components\n","df['Day']=df['Date'].dt.day\n","df['Month']=df['Date'].dt.month\n","df['Year']=df['Date'].dt.year"],"metadata":{"id":"wk-9a2fpoLcV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.drop(['Date'],axis=1,inplace=True) #Removing Date Column"],"metadata":{"id":"Yhx5Iczq8ox6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.describe().columns"],"metadata":{"id":"xckhkB5G8YNb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Chart - 1 visualization code\n","#Vizualizing Density of various features\n","numerical_features=df.describe().columns\n","for col in numerical_features[1:]:\n","    fig = plt.figure(figsize=(9, 6))\n","    ax = fig.gca()\n","    feature = df[col]\n","    sns.distplot(feature,bins=50, ax = ax,color='y')\n","    ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n","    ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)    \n","    ax.set_title(col)\n","plt.show()"],"metadata":{"id":"7v_ESjsspbW7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*By analyzing the density plot of different numerical features,it can be concluded tha*t-\n","\n","Feature with near normal distribution are-\n","  \n","    1-Temperature-(mean-13 degree celcius)\n","\n","    2-Humidity-(mean-58%)\n","\n","\n","Feature with skewed distribution are-\n","\n","    1-Wind Speed-(Mean-1.62 m/s)\n","   \n","    2-Visibility-(Mean-1434 10m)\n","\n","    3-Solar Radiation-(Mean-0.5 MJ/m2)\n","\n","    4-Rainfall-(Mean-0.1 mm)\n","\n","    5-Snowfall-(Mean-0.064 cm)"],"metadata":{"id":"ubnYqPCOXnmi"}},{"cell_type":"markdown","source":["*Analysing the relation of Number of Rented Bike with respect to different numerical features*."],"metadata":{"id":"ac0xIygfeEXT"}},{"cell_type":"code","source":["# Chart - 2 visualization code\n","#Visualizing Relation of Dependent Variable with numerical independent features\n","for col in numerical_features[1:]:\n","    fig = plt.figure(figsize=(9, 6))\n","    ax = fig.gca()\n","    feature = df[col]\n","    label = df['Rented Bike Count']\n","    correlation = feature.corr(label)\n","    plt.scatter(x=feature, y=label)\n","    plt.xlabel(col)\n","    plt.ylabel('Rented Bike Count')\n","    ax.set_title('Rented Bike Count vs ' + col + '- correlation: ' + str(correlation))\n","    z = np.polyfit(df[col], df['Rented Bike Count'], 1)\n","    y_hat = np.poly1d(z)(df[col])\n","\n","    plt.plot(df[col], y_hat, \"r--\", lw=1)\n","\n","plt.show()"],"metadata":{"id":"R4YgtaqtYklH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Conclusion-**\n","\n","1) Most number of bikes rented in between 15 and 20 hrs which shows evening\n","period sees higher demand.\n","\n","2) Temperature having 20 to 30 degree celcius sees highest demand of rental bikes (Automn or Summer season).\n","\n","3) Humidity with 40 to 70 % with maximum demand.\n","\n","4) Lower wind speed increases the demand of Rental Bike.\n","\n","5) Demand of rental bikes increased with higher visibility.\n","\n","6) Higher dew point temperature with greater demand of Rental Bikes.\n","\n","7) Demand decreases with higher Solar Radiations.\n","\n","8) Demand decreases during higher Rainfall and Snowfall."],"metadata":{"id":"6ugg5jszhDLr"}},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"K1UzJvVkm92_"}},{"cell_type":"code","source":["#Removing Outliers\n","df=df[df['Wind speed (m/s)']<=4]\n","df=df[df['Visibility (10m)']>=100]\n","df=df[df['Solar Radiation (MJ/m2)']<=3]\n","df=df[df['Rainfall(mm)']<=10]\n","df=df[df['Snowfall (cm)']<=4]"],"metadata":{"id":"unKEvFdkfonq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Analyzing the relation between rental bike count and numerical features*"],"metadata":{"id":"v8Y4fJT2oTbk"}},{"cell_type":"code","source":["# Chart - 2 visualization code\n","#Vizualizing Relation between categorical features with Dependent Variables\n","for col in numerical_features[1:-2]:\n","    fig = plt.figure(figsize=(9, 6))\n","    ax = fig.gca()\n","    feature = df[col]\n","    label = df['Rented Bike Count']\n","    correlation = feature.corr(label)\n","    plt.scatter(x=feature, y=label)\n","    plt.xlabel(col)\n","    plt.ylabel('Rented Bike Count')\n","    ax.set_title('Rented Bike Count vs ' + col + '- correlation: ' + str(correlation))\n","    z = np.polyfit(df[col], df['Rented Bike Count'], 1)\n","    y_hat = np.poly1d(z)(df[col])\n","\n","    plt.plot(df[col], y_hat, \"r--\", lw=1)\n","\n","plt.show()"],"metadata":{"id":"TSAWjSlbzcdx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" *Analysing Categorical features*"],"metadata":{"id":"jF3VO5TDwU7C"}},{"cell_type":"code","source":["df['Seasons'].value_counts()"],"metadata":{"id":"oB9K2sy2_Opu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["It can be seen that rental bikes are available evenly in different seasons."],"metadata":{"id":"KduTE7Zvx6tD"}},{"cell_type":"code","source":["# Chart - 3 visualization code\n","#ploting Number of Rented bike in different Seasons\n","bike_rented_per_season=df.groupby(['Seasons'])['Rented Bike Count'].mean()\n","plt.rcParams['figure.figsize']=(7,7)\n","sns.barplot(y=bike_rented_per_season,x=bike_rented_per_season.index,data=df)\n","plt.ticklabel_format(style='plain', axis='y')\n","plt.show()"],"metadata":{"id":"t6GMdE67YoAp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can see that demand of Rental Bikes are higher in Automn and Summer Season with average 800 and 1050 respectively while the Winter seen the list minimum demand of nearly 200."],"metadata":{"id":"C8mjf644xBoj"}},{"cell_type":"code","source":["df['Holiday'].value_counts()"],"metadata":{"id":"rWN1DA5N_3ja"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here data show the clearly working days are much more than Holidays."],"metadata":{"id":"MYf2F3CsyMd3"}},{"cell_type":"code","source":["#Visualizing Number of Rented Bike on the Basis of Holiday\n","bike_rented_on_holiday=df.groupby(['Holiday'])['Rented Bike Count'].mean()\n","plt.rcParams['figure.figsize']=(7,7)\n","sns.barplot(y=bike_rented_on_holiday,x=bike_rented_on_holiday.index,data=df)\n","plt.ticklabel_format(style='plain', axis='y')\n","plt.show()"],"metadata":{"id":"F2WIlZ5taOOl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From the bar chart ,it can be clearly seen that demand of Rental bikes are more on working days."],"metadata":{"id":"jltWotKHyvmY"}},{"cell_type":"code","source":["df['Functioning Day'].value_counts()"],"metadata":{"id":"HDJPVF6UAA1L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here we can be seen that Functioning Days are much more than the non functioning days."],"metadata":{"id":"j3HYCw5rzJUB"}},{"cell_type":"code","source":["bike_rented_on_functioning_day=df.groupby(['Functioning Day'])['Rented Bike Count'].mean()\n","plt.rcParams['figure.figsize']=(7,7)\n","sns.barplot(y=bike_rented_on_functioning_day,x=bike_rented_on_functioning_day.index,data=df)\n","plt.ticklabel_format(style='plain', axis='y')\n","plt.show()"],"metadata":{"id":"GFuYTHzndijr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Analysing the correlation among different variables.*"],"metadata":{"id":"n86viaxl0dwp"}},{"cell_type":"code","source":["# Chart - 4 visualization code\n","#Visualizing the correlation among different variable\n","plt.figure(figsize=(15,8))\n","cbar_kws = { \n","            \"shrink\":1,\n","            'extend':'min', \n","            'extendfrac':0.1, \n","            \"ticks\":np.arange(0,22), \n","            \"drawedges\":True,\n","           }\n","correlation = df.corr()\n","sns.heatmap(abs(correlation), annot=True, cmap='coolwarm',linewidth=1,cbar_kws=cbar_kws)"],"metadata":{"id":"irlUoxc8YrdO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From the heatmap it can be seen that-\n","\n","1) Majority of the features are not correlated with each others.\n","\n","2) Temperature has the highest correlation with Dew Point Temperatures.\n","\n","3) While humidity is also highly correlated with visibility."],"metadata":{"id":"IQcVsWaW2OX6"}},{"cell_type":"markdown","source":["Identifying correlating variables with the help of variance inflation factor to get clear pictures.."],"metadata":{"id":"P5EmCIFM3aRR"}},{"cell_type":"code","source":["#Treating Correlating Variables\n","from statsmodels.stats.outliers_influence import variance_inflation_factor\n","def calc_vif(x):\n","  vif=pd.DataFrame()\n","  vif['variable']=x.columns\n","  vif['vif']=[variance_inflation_factor(x.values,i) for i in range(x.shape[1])]\n","  return (vif)"],"metadata":{"id":"rr1biLMl1vsh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calc_vif(df[[i for i in df.describe().columns if i not in ['Rented Bike Count','Day','Month','Year']]])"],"metadata":{"id":"-UekFGmW3heN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calc_vif(df[[i for i in df.describe().columns if i not in ['Rented Bike Count','Day','Month','Year','Dew point temperature(Â°C)']]])"],"metadata":{"id":"UEtBc8a3A6Ql"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Removing the Dew Point Temperature."],"metadata":{"id":"Lx1inWmihXb5"}},{"cell_type":"code","source":["df.drop(['Dew point temperature(Â°C)'],axis=1,inplace=True)"],"metadata":{"id":"_RWjalr4Zb2j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["numerical_features=['Hour','Temperature(Â°C)','Humidity(%)','Wind speed (m/s)','Visibility (10m)','\tSolar Radiation (MJ/m2)','Rainfall(mm)','Snowfall (cm)']"],"metadata":{"id":"Oi1fji9LES_g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let see,the correlation between variables after its treatment."],"metadata":{"id":"U3ZaBULL4nOp"}},{"cell_type":"code","source":["#Visualizing Correlation after treatment\n","plt.figure(figsize=(15,8))\n","correlation = df.corr()\n","sns.heatmap(abs(correlation), annot=True)"],"metadata":{"id":"JpuBSNNIYEgS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["categorical_features=df.describe(include=['object','category']).columns"],"metadata":{"id":"TIJwrbroYuh3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["numerical_features"],"metadata":{"id":"XMW7hUUgfeER"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Analysing the number of rented bike with respect to the different categorical features.*"],"metadata":{"id":"G77D7uB6dnwA"}},{"cell_type":"markdown","source":["First of all we ll plot the boxplot and analyse the density as well as outliers."],"metadata":{"id":"EYd191PdeOgm"}},{"cell_type":"code","source":["#Visualizing outlier through Boxplot\n","for col in categorical_features:\n","    fig = plt.figure(figsize=(9, 6))\n","    ax = fig.gca()\n","    df.boxplot(column = 'Rented Bike Count', by = col, ax = ax)\n","    ax.set_title('Label by ' + col)\n","    ax.set_ylabel(\"Rented Bike Count\")\n","plt.show()"],"metadata":{"id":"Hk4Ufw9PHGeG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After vizualisation we can conclude that-\n","\n","    1-Maximum demand density of rental bike is in Automn and Summer.\n","    2-Above features have higher density of outliers,thus removing them could cause the major data lost."],"metadata":{"id":"oV93sl1de4Fv"}},{"cell_type":"markdown","source":["*Encoding the Categorical Data*"],"metadata":{"id":"u4llj-pJlFct"}},{"cell_type":"markdown","source":["Encoding ll help to process the categorical data by assigning them a numerical values."],"metadata":{"id":"N9B8KvMCl_jg"}},{"cell_type":"code","source":["#Encoding the categorical variables\n","df_pr=df.copy()\n","def encoder(data,columns):\n","  data=pd.concat([data,pd.get_dummies(data[columns],prefix=columns,drop_first=True)],axis=1)\n","  data=data.drop([columns],axis=1)\n","  return data\n","\n","for col in categorical_features:\n","  df_pr=encoder(df_pr,col)\n","df_pr.head()"],"metadata":{"id":"3J3HgbtCXGcU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_pr.drop(['Day','Year'],axis=1,inplace=True)"],"metadata":{"id":"1KE5qSQngKsJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_pr.head()"],"metadata":{"id":"8InoDXtIgnhN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ***7. ML Model Implementation***"],"metadata":{"id":"VfCC591jGiD4"}},{"cell_type":"markdown","source":["Now we ll apply various the Models like-Linear Regression,Random Forest Regression and Polynomial Regression and then after evaluate the results."],"metadata":{"id":"N2e64ZjEmY81"}},{"cell_type":"markdown","source":["*Assigning and Splitting the data for training and testing:*"],"metadata":{"id":"3Xe7wj1ooxn5"}},{"cell_type":"code","source":["\n","# ML Model - 1 Implementation\n","x=df_pr.iloc[:,1:]\n","y=np.sqrt(df_pr.iloc[:,:1])\n","\n","\n","# Fit the Algorithm\n","x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=0)\n","print(x_train.shape)\n","print(x_test.shape)"],"metadata":{"id":"JyAvWolHo5ia"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Scaling the data*"],"metadata":{"id":"eCDne3JErIE5"}},{"cell_type":"markdown","source":["It help out to get rid of impact of the difference in magnitude of the different features."],"metadata":{"id":"BTVZz_XIrTnv"}},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","scaler=MinMaxScaler()\n","x_train=scaler.fit_transform(x_train)\n","x_test=scaler.transform(x_test)"],"metadata":{"id":"COop9I4Ro9kV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`\n","\n","### ML Model - 1-Linear Regression"],"metadata":{"id":"N3EIsEIOpWuf"}},{"cell_type":"markdown","source":["*Implementation*"],"metadata":{"id":"yp_xO9kXrlat"}},{"cell_type":"code","source":["#Implementation\n","reg=LinearRegression().fit(x_train,y_train)"],"metadata":{"id":"7ebyywQieS1U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Model features*"],"metadata":{"id":"GNiZPenirwUI"}},{"cell_type":"code","source":["reg.score(x_train,y_train) "],"metadata":{"id":"mDXYP9gt-B95"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reg.intercept_"],"metadata":{"id":"IDSM-ORM-mRl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reg.coef_ #coefficient of parameter"],"metadata":{"id":"x7X2dXAa-65t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Prediction using the model*"],"metadata":{"id":"DUp9Cp56r4vz"}},{"cell_type":"code","source":["#Prediction\n","y_train_pred=reg.predict(x_train)\n","y_test_pred=reg.predict(x_test)"],"metadata":{"id":"0lpPfdS3_MJS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*It's performance using Evaluation metric Score Chart.*\n","\n","\n"],"metadata":{"id":"ArJBuiUVfxKd"}},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error\n","# Visualizing evaluation Metric Score chart\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import r2_score\n","\n","mse=mean_squared_error(((y_test)**2),((y_test_pred)**2)) \n","print('MSE',mse)\n","\n","mae=mean_absolute_error(((y_test)**2),((y_test_pred)**2))\n","print('MAE',mae)\n","\n","rmse=np.sqrt(mse)\n","print('RMSE',rmse)\n","\n","r2=r2_score(((y_test)**2),((y_test_pred)**2))\n","print('R2',r2)\n","print(\"Adjusted R2 : \",1-(1-r2_score(((y_test)**2), ((y_test_pred)**2)))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)))"],"metadata":{"id":"rqD5ZohzfxKe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here R2_Score is nearly 61% which is very less and generally not acceptable and need further tuning and transformation."],"metadata":{"id":"2lLLx6lMseGy"}},{"cell_type":"code","source":["#Visualizing the relation between the predicted value and actual values.\n","plt.figure(figsize=(8,5))\n","plt.scatter((y_test**2),((y_test_pred)**2),color='brown')\n","plt.xlabel('True_Values')\n","plt.ylabel('Predicted_Values')\n","plt.show()"],"metadata":{"id":"ojl1iBMQHcKf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From the above scatter plot,we can see that higher values giving more sparse values pointing toward the higher error.\n","\n","It shows that model is working well for lower values."],"metadata":{"id":"cyDcZBqMu8dy"}},{"cell_type":"code","source":["error=((y_test)**2)-((y_test_pred)**2)"],"metadata":{"id":"qqVpRI63JHa-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.distplot(error)\n","plt.show()"],"metadata":{"id":"YvYAmxQcJTIb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The above density plot shows the normal distribution of the error,which shows majority of the prediction are having low error."],"metadata":{"id":"BgOq1xMTvhIx"}},{"cell_type":"markdown","source":["# Cross- Validation & Hyperparameter Tuning\n","\n"],"metadata":{"id":"4qY1EAkEfxKe"}},{"cell_type":"markdown","source":["Now we ll try to penalise the coffiecient parameters to reduce the error.\n","\n","Here we ll use three method that are Lasso Regression,Ridge Regression and Elastic Regression and Cross validate them"],"metadata":{"id":"gsRDpyW_wK5C"}},{"cell_type":"markdown","source":["*Lasso Regression*"],"metadata":{"id":"Wm8qcwAb6UVN"}},{"cell_type":"code","source":["#Hyperparameter Tuning using Lasso Regression\n","from sklearn.linear_model import Lasso\n","lasso=Lasso(alpha=0.0001,max_iter=8000)\n","lasso.fit(x_train,y_train) #fitting model"],"metadata":{"id":"IGidvJhPRk7n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lasso.score(x_train,y_train)"],"metadata":{"id":"clMzSpamSQ9f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lasso.coef_"],"metadata":{"id":"AvAjSxIjTY3L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Cross Validation*"],"metadata":{"id":"7xJ_-cdI6aZR"}},{"cell_type":"code","source":["# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n","#Implementing Cross Validation\n","from sklearn.model_selection import GridSearchCV\n","lasso=Lasso()\n","parameters={'alpha':[1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100,0.0014]}\n","lasso_regressor=GridSearchCV(lasso,parameters,scoring='neg_mean_squared_error', cv=5)\n","lasso_regressor.fit(x_train,y_train) #Fitting the model"],"metadata":{"id":"Dy61ujd6fxKe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Best Lasso Parameter*"],"metadata":{"id":"50nENTh__EU6"}},{"cell_type":"code","source":["#Analysing optimal parameter\n","print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)\n","print(\"\\nUsing \",lasso_regressor.best_params_, \" the negative mean squared error is: \", lasso_regressor.best_score_)"],"metadata":{"id":"8nC3xtvVamM2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Prediction through Lasso on test data*"],"metadata":{"id":"LZu0diW8_H7O"}},{"cell_type":"code","source":["#Predicting through model\n","y_pred_lasso=lasso_regressor.predict(x_test) # Prediction on test data"],"metadata":{"id":"9g8hevdWeJo4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Analysing ERROR*\n","\n"],"metadata":{"id":"tdAnOnH6_gFJ"}},{"cell_type":"code","source":["#Visualizing the accuracy of Predicted value with True Value\n","plt.figure(figsize=(8,5))\n","plt.scatter(((y_test)),np.array(y_pred_lasso))\n","plt.xlabel('True_Values')\n","plt.ylabel('Lasso_predicted_Value')\n","plt.show()"],"metadata":{"id":"bGjRnDDwehIK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After visualizing the above ScatterPlot ,we can see increase in linearity of the relationship between True Values and Predicted Values which shows the reduction in error compared to simple Linear Regression Model."],"metadata":{"id":"WzXKjUZq_pWA"}},{"cell_type":"markdown","source":["*Evaluation of Lasso Model*"],"metadata":{"id":"SA6fS5dEAJpj"}},{"cell_type":"code","source":["#Evaluation of Lasso Model\n","MSE  = mean_squared_error(((y_test)**2), (y_pred_lasso)**2)\n","print(\"MSE :\" , MSE)\n","\n","RMSE = np.sqrt(MSE)\n","print(\"RMSE :\" ,RMSE)\n","\n","r2 = r2_score(((y_test)), (y_pred_lasso))\n","print(\"R2 :\" ,r2)\n","print(\"Adjusted R2 : \",1-(1-r2_score(((y_test)), (y_pred_lasso)))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)))"],"metadata":{"id":"w0tyW-1BgSH6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here increase in accuracy can be seen with increase in R2_Score to 67%"],"metadata":{"id":"ySx59AHlAZtR"}},{"cell_type":"markdown","source":["Ridge Regression"],"metadata":{"id":"NKzTAB9GBOBo"}},{"cell_type":"code","source":["#Hyperparameter tuning using Ridge Regression\n","from sklearn.linear_model import Ridge\n","parameters={'alpha' : [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100,0.1]}\n","ridge_regressor=GridSearchCV(Ridge(),parameters,scoring='neg_mean_squared_error',cv=3)\n","ridge_regressor.fit(x_train,y_train) #Fitting the model"],"metadata":{"id":"4oP0EWYGkuOH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Best Parameter on Ridge Regression*"],"metadata":{"id":"XrV6aKEPBVAV"}},{"cell_type":"code","source":["#Analysing the optimal parameters\n","print(\"The best fit alpha value is found out to be :\" ,ridge_regressor.best_params_)\n","print(\"\\nUsing \",ridge_regressor.best_params_, \" the negative mean squared error is: \", ridge_regressor.best_score_)"],"metadata":{"id":"pUPEnYLjnKb_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Prediction using Ridge Regression*"],"metadata":{"id":"3kl-HRHMBadF"}},{"cell_type":"code","source":["#Prediction using Ridge Regression\n","y_pred_train_ridge=ridge_regressor.predict(x_train) #prediction on training data"],"metadata":{"id":"JIzu4iGjpniB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Evaluation of Ridge Regression*"],"metadata":{"id":"XiYAulpcBf58"}},{"cell_type":"code","source":["#Evaluation of model(Ridge)\n","MSE  = mean_squared_error((y_train), (y_pred_train_ridge))\n","print(\"MSE :\" , MSE)\n","\n","RMSE = np.sqrt(MSE)\n","print(\"RMSE :\" ,RMSE)\n","\n","r2 = r2_score((y_train)**2, (y_pred_train_ridge)**2)\n","print(\"R2 :\" ,r2)\n","print(\"Adjusted R2 : \",1-(1-r2_score((y_train), (y_pred_train_ridge)))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)))"],"metadata":{"id":"Y3jo6ZlVrAyQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["On train data,the R2_Score is nearly 58%."],"metadata":{"id":"somlL-4rDCPr"}},{"cell_type":"code","source":["y_pred_ridge=ridge_regressor.predict(x_test) #Prediction on test data"],"metadata":{"id":"Jkqb8vsAnUhK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Evaluating model\n","lr_MSE  = mean_squared_error(((y_test)**2), (y_pred_ridge)**2)\n","print(\"MSE :\" , MSE)\n","\n","lr_RMSE = np.sqrt(MSE)\n","print(\"RMSE :\" ,RMSE)\n","\n","lr_r2 = r2_score(((y_test)**2),(y_pred_ridge)**2)\n","print(\"R2 :\" ,lr_r2)\n","print(\"Adjusted R2 : \",1-(1-r2_score((y_test),(y_pred_ridge)))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)))"],"metadata":{"id":"_3tUhi1inVTt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["On test data,here the R2_Score on test is nearly 60% lesser than Lasso Regression."],"metadata":{"id":"nqZ_vDrtD1FG"}},{"cell_type":"code","source":["#Visualizing the accuracy of Predicted value with True Value\n","plt.figure(figsize=(8,5))\n","plt.scatter((y_test),np.array(y_pred_ridge))\n","plt.xlabel('True_Values')\n","plt.ylabel('Ridge_predicted_Value')\n","plt.show()"],"metadata":{"id":"e2OMoDc1pl0y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here we can see from the above Scatter plot is decrease in density compared to the Lasso Regression which point toward the decrease in Accuracy."],"metadata":{"id":"xHE8NphjEPj2"}},{"cell_type":"markdown","source":["*ElasticNet*"],"metadata":{"id":"ZADiJorZEoGw"}},{"cell_type":"code","source":["#HyperparameterTuning using ElasticNet\n","from sklearn.linear_model import ElasticNet\n","#a * L1 + b * L2\n","#alpha = a + b and l1_ratio = a / (a + b)\n","elasticnet = ElasticNet(alpha=0.1, l1_ratio=0.5)"],"metadata":{"id":"FX__r5advzSS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["elasticnet.fit(x_train,(y_train)) #Fitting the model"],"metadata":{"id":"WBjdp5iQv7IL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["elasticnet.score(x_train, (y_train)) #Evaluating the model"],"metadata":{"id":"M4AD2T23wBv5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In elasticnet,we are getting even worse R2_Score with nearly 50% means least accuracy."],"metadata":{"id":"nhXBth4vFAhp"}},{"cell_type":"markdown","source":["From the above evaluation,we can derive that Lasso Regression is giving best result from different models of Hyper Tuning."],"metadata":{"id":"rzXsvDO8FTwv"}},{"cell_type":"markdown","source":["### ML Model - 2-Random Forest Classifier"],"metadata":{"id":"dJ2tPlVmpsJ0"}},{"cell_type":"markdown","source":["*Implementation of Random Forest Classifier*"],"metadata":{"id":"eNhc86zvGIBg"}},{"cell_type":"code","source":["# Implementation the model\n","from sklearn.ensemble import RandomForestRegressor"],"metadata":{"id":"yEl-hgQWpsJ1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rf = RandomForestRegressor() #Initializing the model\n","grid_search = GridSearchCV(estimator = rf, param_grid = {'n_estimators':[50,80,100],'max_depth':[3,5,7]}, cv = 3, n_jobs = -1, verbose = 2)\n","grid_search.fit(x_train,y_train) #fitting the model"],"metadata":{"id":"svaV5og3ziFQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Prediction using Random Forest Classifier*"],"metadata":{"id":"OedhggdXGPTl"}},{"cell_type":"code","source":["# predicting for both train and test\n","y_pred_train2=grid_search.predict(x_train) #Prediction with Train Data\n","y_pred_test2=grid_search.predict(x_test)  #Prediction with Test Data\n"],"metadata":{"id":"qgBOpXzyCPhc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Evaluation of Random Forest Regressor*"],"metadata":{"id":"QdNL6PR5Gev2"}},{"cell_type":"code","source":["#Model Evaluation on Training set\n","print('The evaluation metric values for training set - Random ForestRegressor with GridSearchCV:')\n","print('The MAE of training set = ',mean_absolute_error(y_train, y_pred_train2))\n","print('The MSE of training set = ',mean_squared_error(y_train, y_pred_train2))\n","print('The R2_score of training set = ',r2_score(y_train, y_pred_train2))"],"metadata":{"id":"NtdOggkzCdeQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Model Evaluation on testing set\n","rf_mae=mean_absolute_error(y_test**2, y_pred_test2**2)\n","rf_mse=mean_squared_error(y_test**2, y_pred_test2**2)\n","rf_r2=r2_score(y_test**2,y_pred_test2**2)\n","\n","print('The evaluation metric values for test set - Linear regression:')\n","print('The MAE of test set = ',mean_absolute_error(y_test**2, y_pred_test2**2))\n","print('The MSE of test set = ',mean_squared_error(y_test**2, y_pred_test2**2))\n","print('The R2_score of test set = ',r2_score(y_test**2,y_pred_test2**2))"],"metadata":{"id":"LjuL8cEIC1K7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here we are getting best good result with R2_Score 77% on test data,much better than the Lasso,Linear Regression"],"metadata":{"id":"t7CRXpIWGpEA"}},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score,confusion_matrix,accuracy_score"],"metadata":{"id":"fib-5d6sLOPJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Visualizing the accuracy of predicted train data with respect to actual train data\n","plt.scatter(y_train,y_pred_train2)\n","plt.xlabel('Actual Values')\n","plt.ylabel('Predicted Values')"],"metadata":{"id":"B0ZePG9GLs-u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Visualizing the accuracy of predicted test data with respect to actual test data\n","plt.scatter(y_test,y_pred_test2)\n","plt.xlabel('Actual Values')\n","plt.ylabel('Predicted Values')"],"metadata":{"id":"FzhwN_VfQxiJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From the scatter plot,we can see the linearity of the relationship between Predicted Values and Actual Values which shows high accuracy and increase in variance with respect to testing data."],"metadata":{"id":"xlOb7MlyITOz"}},{"cell_type":"markdown","source":["*Hypertuning And Cross Validation On Random Forest Regression Model*"],"metadata":{"id":"mD1jv6iPJMZY"}},{"cell_type":"code","source":["#Cross Validation And Hyperparameter Tuning\n","from sklearn.model_selection import GridSearchCV "],"metadata":{"id":"jqUzpE58YA2o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parameters = {'criterion':['squared_error', 'absolute_error', 'poisson'],'max_features':['auto', 'sqrt', 'log2']}"],"metadata":{"id":"oHfVV2niVLgS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Performing the grid search using the parameters with cv of 5\n","grid = GridSearchCV(rf,parameters,cv=5,scoring='neg_mean_squared_error')\n","#Fitting it on our training dataset\n","#grid.fit(x_train,y_train)"],"metadata":{"id":"lq3UD4hMUVJR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Optimal Parameters*"],"metadata":{"id":"f3M0yU-UK_Zo"}},{"cell_type":"code","source":["#grid.best_params_ #Optimal Parameter"],"metadata":{"id":"TORrasW_YY6W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rf_2=RandomForestRegressor(n_estimators=100,random_state=0,criterion='squared_error',max_features='auto',max_depth=15) #Initializing Tuned optimal model"],"metadata":{"id":"i6-RZ_DXcYnw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rf_2.fit(x_train,y_train) #fitting the model"],"metadata":{"id":"NpeEJWE4fIAg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Prediction on Model*"],"metadata":{"id":"9DJ8S7sPLEij"}},{"cell_type":"code","source":["rf_2_y_train_pred=rf_2.predict(x_train) #Prediction on Train Data"],"metadata":{"id":"tum_EMNIfeu7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rf_2_y_test_pred=rf_2.predict(x_test) #Prediction on Test Data"],"metadata":{"id":"DlRRsX2ylCs1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Evaluation*"],"metadata":{"id":"wZyrGEquLL-c"}},{"cell_type":"code","source":["#Evaluation of test data\n","rfc_2_t_mae=mean_absolute_error(y_test**2,rf_2_y_test_pred**2)\n","rfc_2_t_mse=mean_squared_error(y_test**2,rf_2_y_test_pred**2)\n","rfc_2_t_rmse=np.sqrt(mean_squared_error(y_test**2,rf_2_y_test_pred**2))\n","rfc_2_r2=r2_score(y_test**2,rf_2_y_test_pred**2)\n","\n","\n","print('THE MEAN SQUARED ERROR in tuned parameter is : ',mean_squared_error(y_test**2,rf_2_y_test_pred**2))\n","print('THE MEAN ABSOLUTE ERROR in tuned parameter is : ',mean_absolute_error(y_test**2,rf_2_y_test_pred**2))\n","print('THE ROOT MEAN SQUARED ERROR in tuned parameter is : ',np.sqrt(mean_squared_error(y_test**2,rf_2_y_test_pred**2)))\n","print('THE R_2 SCORE in tuned parameter im training data is : ',r2_score(y_train**2,rf_2_y_train_pred**2))\n","print('THE R_2 SCORE in tuned parameter in test data is : ',r2_score(y_test**2,rf_2_y_test_pred**2))"],"metadata":{"id":"RiX55tXnlqpe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This gave the best result with R2_Score 86% on test data which is quiet good score and in acceptable range."],"metadata":{"id":"pNPkcsheLQUZ"}},{"cell_type":"code","source":["#Visualizing the accuracy of predicted train value with respect to actual train value\n","plt.scatter(y_train,rf_2_y_train_pred,color='g')\n","plt.xlabel('Actual Value')\n","plt.ylabel('Predicted Value')"],"metadata":{"id":"u9SpKj1NpHwx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Visualizing the accuracy of predicted test value with respect to actual test value\n","plt.scatter(y_test,rf_2_y_test_pred,color='g')\n","plt.xlabel('Actual Value')\n","plt.ylabel('Predicted Value')"],"metadata":{"id":"_vaCGycoppZK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The above scatter plot shows the increase in linearity and variance with a high accuracy of predicted values with respect to actual values."],"metadata":{"id":"A0cIQPBZTLSa"}},{"cell_type":"markdown","source":["### ML Model - 3-Polynomial Regression"],"metadata":{"id":"Fze-IPXLpx6K"}},{"cell_type":"markdown","source":["*Implementation*"],"metadata":{"id":"CLYRnaJ5UN0u"}},{"cell_type":"code","source":["from sklearn.preprocessing import PolynomialFeatures\n","# ML Model - 3 Implementation\n","\n","# Defining the variables\n","dependent_variable = 'Rented Bike Count'\n","independent_variables = list(set(df_pr.columns[1:].tolist()) - {dependent_variable})\n","\n","x=df_pr.iloc[:,1:]\n","y=np.sqrt(df_pr.iloc[:,:1])\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n","poly_features = PolynomialFeatures(degree=2) #Initializing the model\n","X_train_poly = poly_features.fit_transform(X_train)\n","poly_model = LinearRegression() \n","poly_model.fit(X_train_poly, Y_train) #fitting the model\n","y_train_predicted = poly_model.predict(X_train_poly) #Predicting the model on train data\n","y_test_predict = poly_model.predict(poly_features.fit_transform(X_test)) #Predicting the model on test data\n","#Evaluation of the model\n","poly_mse_test =mean_squared_error(((Y_test)**2), ((y_test_predict)**2))\n","poly_mae_test=mean_absolute_error(((Y_test)**2),((y_test_predict)**2))\n","#poly_rmse_test=np.sqrt(mse_test)"],"metadata":{"id":"FFrSXAtrpx6M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Evaluation*"],"metadata":{"id":"V1iPvb9MUiTp"}},{"cell_type":"code","source":[" print('MEAN SQUARE ERROR OF TEST DATA : ',poly_mse_test)\n"," print('MEAN SQUARE ERROR OF ABSOLUTE DATA : ',poly_mae_test)\n"," #print('ROOT MEAN SQUARE ERROR OF TEST DATA : ',poly_rmse_test)"],"metadata":{"id":"m5Ce57QjanQo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["r2_poly_train=r2_score(((Y_train)**2),((y_train_predicted)**2)) #Evaluation\n","r2_poly_test=r2_score(((Y_test)**2),((y_test_predict)**2))"],"metadata":{"id":"eSVXuaSKpx6M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('r2_score of polynomial_train_data',r2_poly_train)\n","print('r2_score of polynomial_test_data',r2_poly_test)"],"metadata":{"id":"8xcqj2-AT-Qe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Its R2_Score is quiet acceptable with 72% on test data but lower than the Random Forest Regression Model."],"metadata":{"id":"a-D5ixxDU9EX"}},{"cell_type":"code","source":["#Vizualizing the predicted train data with respect to the actual train data\n","plt.scatter(Y_train,y_train_predicted)\n","plt.xlabel('Actual value'),plt.ylabel('Predicted value')\n","plt.title('Training Error')\n","plt.show()"],"metadata":{"id":"LxNxQJseXfrd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Vizualising the predicted test data with respect to the actual test data\n","plt.scatter(Y_test,y_test_predict)\n","plt.xlabel('Actual value'),plt.ylabel('Predicted value')\n","plt.title('Test Error')\n","plt.show()"],"metadata":{"id":"Qqyp_I4iZqJx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From the above Scatter Plot we can visualize the accuracy of the Predicted Values with respect to Actual Values."],"metadata":{"id":"XEKon2VuVbLV"}},{"cell_type":"code","source":["#Visualizing error density\n","error_poly=((Y_test)**2)-((y_test_predict)**2)\n","sns.distplot(error_poly)"],"metadata":{"id":"M1BZTuPTaQgB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","print(\"Skewness: %f\" % error_poly.skew())\n","print(\"Kurtosis: %f\" % error_poly.kurt())"],"metadata":{"id":"EnSlM0LqWylD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here we can see that despite skewness is under acceptable range,its Kurtosis is quiet high."],"metadata":{"id":"xfwzRPGFXE9-"}},{"cell_type":"markdown","source":["Here Error density follows the normal distribution"],"metadata":{"id":"HbXcgTTXWTTI"}},{"cell_type":"markdown","source":["# **Comparison**"],"metadata":{"id":"yZHupLZ5ih02"}},{"cell_type":"markdown","source":["*Mean Squared Error*"],"metadata":{"id":"05Ga70xQrlk-"}},{"cell_type":"code","source":["#Comparison of different model with respect to following metrics\n","#MEAN SQUARE ERROR\n","model=['Linear Regression','RANDOM FOREST REGRESSION','TUNED RFC','POLYNOMIAL REGRESSION']\n","acc=[lr_MSE,rf_mse,rfc_2_t_mse,poly_mse_test]\n","plt.figure(figsize=(12,8))\n","sns.barplot(x=model,y=acc)\n","plt.xlabel('Model')\n","plt.ylabel('MEAN SQUARED ERROR')\n"],"metadata":{"id":"KpZkUIJUTzsU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From the above Barplot we can visualize that Tuned Random forest Regression Model gives the least Mean Squarred Error with less than 60000 while Linear Regression Model gives the Maximum Mean Squared Error with more than 140000."],"metadata":{"id":"BSz-F1fMYMru"}},{"cell_type":"markdown","source":["*R2_Score*"],"metadata":{"id":"ct8DL2NOrzkj"}},{"cell_type":"code","source":["#R2_SCORE\n","model=['Linear Regression','RANDOM FOREST REGRESSION','TUNED RFC','POLYNOMIAL REGRESSION']\n","acc=[lr_r2,rf_r2,rfc_2_r2,r2_poly_test]\n","plt.figure(figsize=(12,8))\n","sns.barplot(x=model,y=acc)\n","plt.xlabel('Model')\n","plt.ylabel('R2_SCORE')\n"],"metadata":{"id":"DuneIy2yT2i_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If we compare the R2_Score of the different models,we can see that the Tuned Random Forest Model gives the maximum accuracy with more than 85% while Linear Regression gives minimum accuracy with less than 60%."],"metadata":{"id":"Q49-RDoyZCEj"}},{"cell_type":"markdown","source":["# Analysing importance of different features"],"metadata":{"id":"vbcx37CoiqOc"}},{"cell_type":"markdown","source":["If we take the best fit model the we have to choose here is Random Forest Model then after we ll try to find the importance of the features."],"metadata":{"id":"fY7ItriNZ99M"}},{"cell_type":"code","source":["#feature importance in tuned random forest classifier\n","rf_optimal_model=grid_search.best_estimator_\n","rf_optimal_model"],"metadata":{"id":"R9Cj_DgXJxQp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rf_optimal_model.feature_importances_"],"metadata":{"id":"3VMIUS9XKPFo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["importances=rf_optimal_model.feature_importances_"],"metadata":{"id":"wk8APL7BLCZX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["importance_dict = {'Feature' : list(x.columns),\n","                   'Feature Importance' : importances}\n","\n","importance_df = pd.DataFrame(importance_dict)"],"metadata":{"id":"VHZ94umGOQ3A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["importance_df['Feature Importance'] = round(importance_df['Feature Importance'],2)"],"metadata":{"id":"mOuncX5iOpa3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["importance_df=importance_df.sort_values(by=['Feature Importance'],ascending=False)"],"metadata":{"id":"rNP82vbYQtPO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["importance_df.head(10).reset_index()"],"metadata":{"id":"gFSYLGImPboq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# visualizing feature importance \n","plt.figure(figsize=(8,8))\n","plt.title('Feature Importance')\n","sns.barplot(x=importance_df['Feature Importance'],y=importance_df['Feature'],hue=importance_df['Feature'])"],"metadata":{"id":"NdQwMwbpS4vL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From the above bar chart we can see that the Temperature and Time(Hour) play the maximum role in affecting the demand of the Rental Bike."],"metadata":{"id":"wxseQqoWatGz"}},{"cell_type":"markdown","source":["# Model Explainabilty"],"metadata":{"id":"jD-CGy6KjTw7"}},{"cell_type":"markdown","source":["*Explaination of model using Eli5.*"],"metadata":{"id":"J6Lj3Xb7elKQ"}},{"cell_type":"code","source":["pip install eli5"],"metadata":{"id":"5N3KmAS_UCI9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import eli5 as eli"],"metadata":{"id":"yRNFLe2iQIvE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eli.explain_weights(rf_2)"],"metadata":{"id":"-vE88uTZUIGQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eli.explain_prediction(rf_2 , np.array(x_test)[1])"],"metadata":{"id":"BgQimW9zUyu6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eli.show_prediction(rf_2, x_test[1],\n","                    feature_names=list(x.columns),\n","                    show_feature_values=True)"],"metadata":{"id":"xMVPupD5VW6l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here,according to Eli5,Temperature and time have negative contribution  on demand with a higher values."],"metadata":{"id":"aPOtGUD9fOyD"}}]}